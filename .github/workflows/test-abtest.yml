name: Test ABTest Functionality

on:
  workflow_dispatch:
    inputs:
      expert:
        description: 'Expert file path'
        required: true
        default: 'experts/programming-expert.md'
      baseline:
        description: 'Baseline prompt path'
        required: true
        default: 'test-prompts/programming-baseline.md'
      variant:
        description: 'Variant prompt path'
        required: true
        default: 'test-prompts/programming-variant.md'
      context_files:
        description: 'Context files (comma-separated)'
        required: false
        default: 'scripts/abtest.js,scripts/template-helper.js'
  push:
    paths:
      - 'scripts/abtest.js'
      - 'templates/abtest-evaluation.md'
      - 'test-prompts/**'
      - '.github/workflows/test-abtest.yml'

jobs:
  test-abtest:
    runs-on: ubuntu-latest
    
    steps:
    - name: Checkout repository
      uses: actions/checkout@v3
    
    - name: Setup Node.js
      uses: actions/setup-node@v3
      with:
        node-version: '18'
    
    - name: Install dependencies
      run: |
        npm install @octokit/rest @anthropic-ai/sdk dotenv
    
    - name: Create test script
      run: |
        cat << 'EOF' > run-abtest.js
        const { ABTest } = require('./scripts/abtest');
        const { Octokit } = require('@octokit/rest');
        const Anthropic = require('@anthropic-ai/sdk');

        async function runTest() {
          console.log('üß™ GitHub Actions ABTest Validation\n');
          console.log('=====================================\n');
          
          const octokit = new Octokit({
            auth: process.env.GITHUB_TOKEN
          });
          
          const anthropic = new Anthropic({
            apiKey: process.env.ANTHROPIC_API_KEY
          });
          
          const abTest = new ABTest({
            octokit,
            anthropic,
            owner: 'whichguy',
            repo: 'prompt-expert-bank'
          });
          
          // Parse inputs
          const expert = process.env.EXPERT_PATH || 'experts/programming-expert.md';
          const baseline = process.env.BASELINE_PATH || 'test-prompts/programming-baseline.md';
          const variant = process.env.VARIANT_PATH || 'test-prompts/programming-variant.md';
          const contextFiles = process.env.CONTEXT_FILES ? 
            process.env.CONTEXT_FILES.split(',').map(f => f.trim()) : 
            ['scripts/abtest.js', 'scripts/template-helper.js'];
          
          const testConfig = {
            expert: expert,
            promptA: baseline,
            promptB: variant,
            context: contextFiles,
            testScenario: 'Validate email addresses with production-quality code'
          };
          
          console.log('üìã Configuration:');
          console.log(JSON.stringify(testConfig, null, 2));
          console.log('\n‚è≥ Running evaluation...\n');
          
          try {
            const result = await abTest.run(testConfig);
            
            if (!result.success) {
              throw new Error(result.error || 'Test failed');
            }
            
            console.log('‚úÖ Evaluation Complete!\n');
            console.log('üìä Results:');
            console.log('- Winner:', result.winner);
            console.log('- Confidence:', result.confidence);
            
            if (result.threads) {
              console.log('\nüìù Response Analysis:');
              console.log('- Baseline length:', result.threads.baseline?.length || 0, 'chars');
              console.log('- Variant length:', result.threads.variant?.length || 0, 'chars');
              
              // Output evaluation for artifact
              console.log('\n‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê');
              console.log('EVALUATION OUTPUT:');
              console.log('‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê\n');
              console.log(result.threads.evaluation);
              console.log('\n‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê');
              
              // Performance metrics
              if (result.metrics) {
                console.log('\n‚ö° Performance Metrics:');
                console.log('Baseline:', JSON.stringify(result.metrics.baseline, null, 2));
                console.log('Variant:', JSON.stringify(result.metrics.variant, null, 2));
                
                // Calculate differences
                const speedDiff = ((result.metrics.variant.latency - result.metrics.baseline.latency) / result.metrics.baseline.latency * 100).toFixed(1);
                const tokenDiff = ((result.metrics.variant.totalTokens - result.metrics.baseline.totalTokens) / result.metrics.baseline.totalTokens * 100).toFixed(1);
                
                console.log('\nüìà Performance Comparison:');
                console.log(`- Speed: Variant is ${speedDiff > 0 ? speedDiff + '% slower' : Math.abs(speedDiff) + '% faster'}`);
                console.log(`- Tokens: Variant uses ${tokenDiff > 0 ? tokenDiff + '% more' : Math.abs(tokenDiff) + '% fewer'} tokens`);
              }
            }
            
            // Create summary for PR comment if applicable
            if (process.env.GITHUB_EVENT_NAME === 'pull_request') {
              const summary = `## üß™ A/B Test Results\n\n` +
                `**Winner:** ${result.winner}\n` +
                `**Confidence:** ${result.confidence}\n\n` +
                `### Configuration\n` +
                `- Expert: \`${expert}\`\n` +
                `- Baseline: \`${baseline}\`\n` +
                `- Variant: \`${variant}\`\n` +
                `- Context Files: ${contextFiles.length}\n\n` +
                `[View Full Workflow Run](https://github.com/${{ github.repository }}/actions/runs/${{ github.run_id }})`;
              
              require('fs').writeFileSync('test-summary.md', summary);
            }
            
            process.exit(0);
          } catch (error) {
            console.error('‚ùå Test failed:', error.message);
            process.exit(1);
          }
        }
        
        runTest();
        EOF
    
    - name: Run ABTest
      env:
        GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}
        ANTHROPIC_API_KEY: ${{ secrets.ANTHROPIC_API_KEY }}
        EXPERT_PATH: ${{ github.event.inputs.expert }}
        BASELINE_PATH: ${{ github.event.inputs.baseline }}
        VARIANT_PATH: ${{ github.event.inputs.variant }}
        CONTEXT_FILES: ${{ github.event.inputs.context_files }}
      run: node run-abtest.js
    
    - name: Upload test results
      if: always()
      uses: actions/upload-artifact@v3
      with:
        name: abtest-evaluation-${{ github.run_number }}
        path: |
          test-summary.md
          run-abtest.js
    
    - name: Comment PR (if applicable)
      if: github.event_name == 'pull_request' && success()
      uses: actions/github-script@v6
      with:
        script: |
          const fs = require('fs');
          const summary = fs.readFileSync('test-summary.md', 'utf8');
          github.rest.issues.createComment({
            issue_number: context.issue.number,
            owner: context.repo.owner,
            repo: context.repo.repo,
            body: summary
          });