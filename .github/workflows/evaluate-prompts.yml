name: Evaluate Prompt Changes

on:
  workflow_call:
    inputs:
      pr-number:
        required: true
        type: string
      repository:
        required: true
        type: string
      auto-close-on-fail:
        required: false
        type: boolean
        default: true
        description: 'Automatically close PR if evaluation fails'
    secrets:
      github-token:
        required: true
      anthropic-api-key:
        required: true

jobs:
  evaluate:
    runs-on: ubuntu-latest
    permissions:
      contents: write
      pull-requests: write
      issues: write
    steps:
      - name: Checkout Expert Bank
        uses: actions/checkout@v3
        with:
          repository: whichguy/prompt-expert-bank
          
      - name: Setup Node.js
        uses: actions/setup-node@v3
        with:
          node-version: '18'
          
      - name: Create package.json if needed
        run: |
          if [ ! -f package.json ]; then
            npm init -y
          fi
          
      - name: Install dependencies
        run: |
          npm install @anthropic-ai/sdk@0.24.0 @octokit/rest@19.0.0 @actions/core@1.10.0 @actions/github@5.1.1
        
      - name: Run evaluation
        env:
          GITHUB_TOKEN: ${{ secrets.github-token }}
          ANTHROPIC_API_KEY: ${{ secrets.anthropic-api-key }}
        run: |
          # Parse repository input
          IFS='/' read -r OWNER REPO <<< "${{ inputs.repository }}"
          
          # Create generic evaluation script
          cat > evaluate.js << 'EOF'
          const fs = require('fs');
          const path = require('path');
          const { Anthropic } = require('@anthropic-ai/sdk');
          const { Octokit } = require('@octokit/rest');
          
          const OWNER = process.env.OWNER;
          const REPO = process.env.REPO;
          const PR_NUMBER = parseInt(process.env.PR_NUMBER);
          
          async function evaluate() {
            const octokit = new Octokit({ auth: process.env.GITHUB_TOKEN });
            const anthropic = new Anthropic({ apiKey: process.env.ANTHROPIC_API_KEY });
            
            console.log(`Evaluating PR #${PR_NUMBER} in ${OWNER}/${REPO}`);
            
            try {
              // Get PR files
              const { data: files } = await octokit.pulls.listFiles({
                owner: OWNER,
                repo: REPO,
                pull_number: PR_NUMBER
              });
              
              const promptFiles = files.filter(f => 
                f.filename.includes('prompt') && 
                (f.filename.endsWith('.md') || f.filename.endsWith('.txt'))
              );
              
              if (promptFiles.length === 0) {
                await octokit.issues.createComment({
                  owner: OWNER,
                  repo: REPO,
                  issue_number: PR_NUMBER,
                  body: 'âŒ No prompt files found in this PR'
                });
                return;
              }
              
              // Detect domain from filename and content
              let domain = null;
              
              for (const file of promptFiles) {
                const newContent = await getFileContent(octokit, OWNER, REPO, file.filename, null, 'head');
                
                // Try to detect domain from filename or content
                if (file.filename.includes('security') || newContent.toLowerCase().includes('security') ||
                   newContent.toLowerCase().includes('risk') || newContent.toLowerCase().includes('safety')) {
                  domain = 'security';
                } else if (file.filename.includes('code') || file.filename.includes('programming') || 
                         newContent.toLowerCase().includes('code review') || newContent.toLowerCase().includes('programming') ||
                         newContent.toLowerCase().includes('javascript') || newContent.toLowerCase().includes('python') ||
                         newContent.toLowerCase().includes('java') || newContent.toLowerCase().includes('react') ||
                         newContent.toLowerCase().includes('api') || newContent.toLowerCase().includes('function') ||
                         newContent.toLowerCase().includes('algorithm') || newContent.toLowerCase().includes('debug')) {
                  domain = 'programming';
                } else if (file.filename.includes('data') || newContent.toLowerCase().includes('data analysis') ||
                          newContent.toLowerCase().includes('analytics') || newContent.toLowerCase().includes('visualization')) {
                  domain = 'data-analysis';
                } else if (file.filename.includes('financial') || newContent.toLowerCase().includes('financial') ||
                          newContent.toLowerCase().includes('finance') || newContent.toLowerCase().includes('budget') ||
                          newContent.toLowerCase().includes('investment') || newContent.toLowerCase().includes('money')) {
                  domain = 'financial';
                } else {
                  // Default to general purpose expert for unmatched prompts
                  domain = 'general';
                }
                
                if (domain) break;
              }
              
              // Domain detection now always succeeds with 'general' as fallback
              
              // Load MD-based expert definition
              const expertPath = path.join(__dirname, 'expert-definitions', `${domain}-expert.md`);
              
              if (!fs.existsSync(expertPath)) {
                await octokit.issues.createComment({
                  owner: OWNER,
                  repo: REPO,
                  issue_number: PR_NUMBER,
                  body: `âš ï¸ No expert definition found for domain: ${domain}. Please check available experts in expert-definitions/.`
                });
                return;
              }
              
              // Read expert definition
              const expertDefinition = fs.readFileSync(expertPath, 'utf-8');
              
              // Get PR history for learning context
              const prHistory = await getPRHistory(octokit, OWNER, REPO);
              
              // Create MD-based expert module
              const expertModule = {
                name: `${domain.charAt(0).toUpperCase() + domain.slice(1)} Expert`,
                definition: expertDefinition,
                async evaluatePrompts(oldContent, newContent, anthropic) {
                  // Use 3-thread evaluation model as designed
                  
                  // Thread A: Evaluate current prompt
                  const threadA = await anthropic.messages.create({
                    model: 'claude-3-5-sonnet-20241022',
                    max_tokens: 4000,
                    messages: [{
                      role: 'user',
                      content: `You are primed with this prompt definition:\n\n${oldContent}\n\nNow respond to this test scenario: "Analyze the command 'sudo rm -rf /var/lib/docker' in a production environment"`
                    }]
                  });
                  
                  // Thread B: Evaluate new prompt  
                  const threadB = await anthropic.messages.create({
                    model: 'claude-3-5-sonnet-20241022',
                    max_tokens: 4000,
                    messages: [{
                      role: 'user',
                      content: `You are primed with this prompt definition:\n\n${newContent}\n\nNow respond to this test scenario: "Analyze the command 'sudo rm -rf /var/lib/docker' in a production environment"`
                    }]
                  });
                  
                  // Thread C: Expert comparison with PR history context
                  const comparison = await anthropic.messages.create({
                    model: 'claude-3-5-sonnet-20241022',
                    max_tokens: 4000,
                    messages: [{
                      role: 'user',
                      content: `${expertDefinition}\n\n## PR History Context\n\n${prHistory}\n\n**IMPORTANT**: Consider all learnings from the PR history above. Newer evaluations should override older knowledge when there are conflicts. Use this historical context to inform your evaluation criteria and decision-making process.\n\n## Evaluation Task\n\nCompare these two security prompt responses:\n\n**Candidate A (Current):**\n${threadA.content[0].text}\n\n**Candidate B (Proposed):**\n${threadB.content[0].text}\n\nProvide a detailed evaluation considering the PR history context and make a binary decision: APPROVE (merge PR) or REQUEST_CHANGES (close PR).`
                    }]
                  });
                  
                  const expertResponse = comparison.content[0].text;
                  
                  // Intelligent approval logic
                  let recommendation = 'REQUEST_CHANGES';
                  
                  // Check for explicit approval
                  if (expertResponse.toLowerCase().includes('decision: approve') || 
                      expertResponse.toLowerCase().includes('recommendation: approve')) {
                    recommendation = 'APPROVE';
                  }
                  
                  // Score-based approval (extract scores like "9.4/10" or "Candidate B: 9.4/10")
                  const scoreMatches = expertResponse.match(/candidate b[:\s]*(\d+\.?\d*)/i);
                  if (scoreMatches) {
                    const score = parseFloat(scoreMatches[1]);
                    if (score >= 8.5) {
                      recommendation = 'APPROVE';
                      console.log(`Auto-approving based on high score: ${score}/10`);
                    }
                  }
                  
                  // Check for "excellent" or "superior" language with high scores
                  if (expertResponse.toLowerCase().includes('excellent') || 
                      expertResponse.toLowerCase().includes('superior')) {
                    const anyScore = expertResponse.match(/(\d+\.?\d*)\/10/g);
                    if (anyScore && anyScore.some(s => parseFloat(s) >= 8.0)) {
                      recommendation = 'APPROVE';
                      console.log('Auto-approving based on excellent feedback with high scores');
                    }
                  }
                  
                  return {
                    report: `### ðŸ” 3-Thread Evaluation Results\n\n**Test Scenario:**\n"Analyze the command 'sudo rm -rf /var/lib/docker' in a production environment"\n\n**Thread A (Current Prompt Response):**\n${threadA.content[0].text}\n\n**Thread B (Proposed Prompt Response):**\n${threadB.content[0].text}\n\n**Thread C (Expert Analysis):**\n${expertResponse}\n\n`,
                    recommendation: recommendation,
                    improvement: recommendation === 'APPROVE' ? 1 : 0
                  };
                }
              };
              
              // Process each changed file
              let fullReport = `## ðŸ¦ Prompt Expert Bank - Evaluation Report\n\n`;
              fullReport += `*Domain Expert: ${expertModule.name || domain}*\n`;
              fullReport += `*Timestamp: ${new Date().toISOString()}*\n\n`;
              
              let overallRecommendation = 'APPROVE';
              let totalImprovement = 0;
              
              for (const file of promptFiles) {
                fullReport += `## ðŸ“„ File: ${file.filename}\n\n`;
                fullReport += `### Change Summary\n`;
                fullReport += `- **Status**: ${file.status}\n`;
                fullReport += `- **Lines changed**: +${file.additions} -${file.deletions}\n\n`;
                
                // Get the old and new content
                const oldContent = file.status === 'added' ? '' : await getFileContent(octokit, OWNER, REPO, file.filename, file.previous_filename, 'base');
                const newContent = await getFileContent(octokit, OWNER, REPO, file.filename, null, 'head');
                
                // Use expert module to evaluate
                const evaluation = await expertModule.evaluatePrompts(oldContent, newContent, anthropic);
                
                // Add evaluation results to report
                fullReport += evaluation.report || '### Evaluation Results\n\nNo detailed report provided by expert module.\n\n';
                
                // Update overall recommendation based on expert evaluation
                if (evaluation.recommendation === 'REJECT' || evaluation.recommendation === 'REQUEST_CHANGES') {
                  overallRecommendation = 'REQUEST_CHANGES';
                }
                
                if (evaluation.improvement !== undefined) {
                  totalImprovement += evaluation.improvement;
                }
              }
              
              // Add final recommendation - NEVER NEUTRAL
              fullReport += `## ðŸŽ¯ Final Recommendation\n\n`;
              
              if (overallRecommendation === 'APPROVE') {
                fullReport += `### âœ… APPROVE\n\n`;
                fullReport += `The changes are acceptable and ready for merge.\n\n`;
                fullReport += `**Ready to merge** âœ…`;
              } else {
                // All non-APPROVE cases become REQUEST_CHANGES
                fullReport += `### âŒ REQUEST CHANGES\n\n`;
                fullReport += `The changes need improvement before merging.\n\n`;
                fullReport += `**Needs revision** âŒ`;
              }
              
              // Post comment
              await octokit.issues.createComment({
                owner: OWNER,
                repo: REPO,
                issue_number: PR_NUMBER,
                body: fullReport
              });
              
              // Handle PR actions based on evaluation result
              const autoCloseOnFail = process.env.AUTO_CLOSE_ON_FAIL !== 'false';
              
              if (overallRecommendation === 'APPROVE') {
                // Auto-merge approved PRs
                console.log('Merging PR due to successful evaluation...');
                try {
                  await octokit.pulls.merge({
                    owner: OWNER,
                    repo: REPO,
                    pull_number: PR_NUMBER,
                    commit_title: `PromptExpert approved merge`,
                    commit_message: `Automatically merged after expert evaluation approval.\n\nâœ… Expert recommendation: APPROVE\nðŸ“Š Evaluation completed: ${new Date().toISOString()}\nðŸ¤– Merged by PromptExpert system`,
                    merge_method: 'squash'
                  });
                  
                  await octokit.issues.createComment({
                    owner: OWNER,
                    repo: REPO,
                    issue_number: PR_NUMBER,
                    body: `ðŸŽ‰ **PR automatically merged** after expert approval!\n\nâœ… Expert evaluation: APPROVED\nðŸš€ Changes are now live in main branch.`
                  });
                } catch (mergeError) {
                  console.error('Failed to merge PR:', mergeError.message);
                  await octokit.issues.createComment({
                    owner: OWNER,
                    repo: REPO,
                    issue_number: PR_NUMBER,
                    body: `âœ… **Expert approved** but auto-merge failed: ${mergeError.message}\n\nPlease merge manually - the evaluation was successful!`
                  });
                }
              } else if (autoCloseOnFail) {
                // Auto-close failed PRs
                console.log('Closing PR due to failed evaluation...');
                await octokit.pulls.update({
                  owner: OWNER,
                  repo: REPO,
                  pull_number: PR_NUMBER,
                  state: 'closed'
                });
                
                await octokit.issues.createComment({
                  owner: OWNER,
                  repo: REPO,
                  issue_number: PR_NUMBER,
                  body: `ðŸš« **PR automatically closed** due to failed security evaluation.\n\nPlease address the feedback above and submit a new PR with the improvements.`
                });
              }
              
              console.log('Evaluation completed successfully');
              
            } catch (error) {
              console.error('Evaluation error:', error);
              await octokit.issues.createComment({
                owner: OWNER,
                repo: REPO,
                issue_number: PR_NUMBER,
                body: `âŒ Evaluation failed: ${error.message}`
              });
              throw error;
            }
          }
          
          async function getPRHistory(octokit, owner, repo) {
            try {
              // Get all closed PRs with prompt changes (last 20 for context)
              console.log('Fetching PR history for learning context...');
              const { data: prs } = await octokit.pulls.list({
                owner: owner,
                repo: repo,
                state: 'all',
                sort: 'updated',
                direction: 'desc',
                per_page: 20
              });
              
              let historyContext = '### Recent PR Evaluation History\n\n';
              
              for (const pr of prs) {
                // Skip current PR
                if (pr.number === parseInt(process.env.PR_NUMBER)) continue;
                
                // Check if PR had prompt-related files
                const { data: files } = await octokit.pulls.listFiles({
                  owner: owner,
                  repo: repo,
                  pull_number: pr.number
                }).catch(() => ({ data: [] }));
                
                const hasPromptFiles = files.some(f => 
                  f.filename.includes('prompt') && 
                  (f.filename.endsWith('.md') || f.filename.endsWith('.txt'))
                );
                
                if (!hasPromptFiles) continue;
                
                // Get evaluation comments
                const { data: comments } = await octokit.issues.listComments({
                  owner: owner,
                  repo: repo,
                  issue_number: pr.number
                }).catch(() => ({ data: [] }));
                
                const expertComments = comments.filter(c => 
                  c.body.includes('Prompt Expert Bank') || 
                  c.body.includes('Expert evaluation') ||
                  c.body.includes('Thread A') ||
                  c.body.includes('Thread B')
                );
                
                if (expertComments.length > 0) {
                  historyContext += `**PR #${pr.number}** (${pr.state.toUpperCase()}): ${pr.title}\n`;
                  historyContext += `Status: ${pr.merged_at ? 'MERGED' : pr.state.toUpperCase()}\n`;
                  historyContext += `Files changed: ${files.filter(f => f.filename.includes('prompt')).map(f => f.filename).join(', ')}\n`;
                  
                  // Include key insights from expert evaluation
                  const lastExpertComment = expertComments[expertComments.length - 1];
                  if (lastExpertComment) {
                    const body = lastExpertComment.body;
                    // Extract key decision and scoring info
                    const decisionMatch = body.match(/(APPROVE|REQUEST_CHANGES|REJECT)/g);
                    const scoreMatch = body.match(/(\d+\.?\d*)\s*\/\s*10/g);
                    
                    if (decisionMatch) {
                      historyContext += `Expert Decision: ${decisionMatch[decisionMatch.length - 1]}\n`;
                    }
                    if (scoreMatch) {
                      historyContext += `Scores Found: ${scoreMatch.join(', ')}\n`;
                    }
                    
                    // Extract improvement insights if available
                    const improvementMatch = body.match(/(?:improvement|better|superior|excellent)[^.]*[.!]/gi);
                    if (improvementMatch && improvementMatch.length > 0) {
                      historyContext += `Key Insights: ${improvementMatch.slice(0, 2).join(' ')}\n`;
                    }
                  }
                  
                  historyContext += `Updated: ${pr.updated_at}\n\n`;
                }
              }
              
              if (historyContext === '### Recent PR Evaluation History\n\n') {
                historyContext += 'No previous prompt evaluations found in recent PR history.\n\n';
              }
              
              historyContext += '**Learning Directive**: Use this history to:\n';
              historyContext += '1. Identify patterns in what makes prompts better\n';
              historyContext += '2. Apply consistent evaluation criteria\n';
              historyContext += '3. Learn from past scoring decisions\n';
              historyContext += '4. Override older learnings with newer insights\n';
              historyContext += '5. Maintain continuity in evaluation standards\n\n';
              
              return historyContext;
              
            } catch (error) {
              console.log(`Could not fetch PR history: ${error.message}`);
              return '### PR History Context\n\nNo previous evaluation history available.\n\n';
            }
          }
          
          async function getFileContent(octokit, owner, repo, path, previousPath, refType) {
            try {
              let ref;
              if (refType === 'head') {
                // Get from PR branch
                ref = `refs/pull/${process.env.PR_NUMBER}/head`;
              } else if (refType === 'base') {
                // Get from base branch
                ref = process.env.GITHUB_BASE_REF || 'main';
              } else {
                // Default behavior
                ref = process.env.GITHUB_BASE_REF || 'main';
              }
              
              const { data } = await octokit.repos.getContent({
                owner: owner,
                repo: repo,
                path: previousPath || path,
                ref: ref
              });
              
              if (data.content) {
                return Buffer.from(data.content, 'base64').toString('utf-8');
              }
            } catch (error) {
              console.log(`Could not fetch previous version of ${path}: ${error.message}`);
            }
            return '';
          }
          
          evaluate().catch(err => {
            console.error(err);
            process.exit(1);
          });
          EOF
          
          # Run evaluation
          OWNER="${OWNER}" REPO="${REPO}" PR_NUMBER="${{ inputs.pr-number }}" GITHUB_BASE_REF="${{ github.base_ref }}" AUTO_CLOSE_ON_FAIL="${{ inputs.auto-close-on-fail }}" node evaluate.js