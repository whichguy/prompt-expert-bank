name: Evaluate Prompt Changes

on:
  workflow_call:
    inputs:
      pr-number:
        required: true
        type: string
      repository:
        required: true
        type: string
      auto-close-on-fail:
        required: false
        type: boolean
        default: true
        description: 'Automatically close PR if evaluation fails'
    secrets:
      github-token:
        required: true
      anthropic-api-key:
        required: true

jobs:
  evaluate:
    runs-on: ubuntu-latest
    permissions:
      contents: read
      pull-requests: write
      issues: write
    steps:
      - name: Checkout Expert Bank
        uses: actions/checkout@v3
        with:
          repository: whichguy/prompt-expert-bank
          
      - name: Setup Node.js
        uses: actions/setup-node@v3
        with:
          node-version: '18'
          
      - name: Create package.json if needed
        run: |
          if [ ! -f package.json ]; then
            npm init -y
          fi
          
      - name: Install dependencies
        run: |
          npm install @anthropic-ai/sdk@0.24.0 @octokit/rest@19.0.0 @actions/core@1.10.0 @actions/github@5.1.1
        
      - name: Run evaluation
        env:
          GITHUB_TOKEN: ${{ secrets.github-token }}
          ANTHROPIC_API_KEY: ${{ secrets.anthropic-api-key }}
        run: |
          # Parse repository input
          IFS='/' read -r OWNER REPO <<< "${{ inputs.repository }}"
          
          # Create generic evaluation script
          cat > evaluate.js << 'EOF'
          const fs = require('fs');
          const path = require('path');
          const { Anthropic } = require('@anthropic-ai/sdk');
          const { Octokit } = require('@octokit/rest');
          
          const OWNER = process.env.OWNER;
          const REPO = process.env.REPO;
          const PR_NUMBER = parseInt(process.env.PR_NUMBER);
          
          async function evaluate() {
            const octokit = new Octokit({ auth: process.env.GITHUB_TOKEN });
            const anthropic = new Anthropic({ apiKey: process.env.ANTHROPIC_API_KEY });
            
            console.log(`Evaluating PR #${PR_NUMBER} in ${OWNER}/${REPO}`);
            
            try {
              // Get PR files
              const { data: files } = await octokit.pulls.listFiles({
                owner: OWNER,
                repo: REPO,
                pull_number: PR_NUMBER
              });
              
              const promptFiles = files.filter(f => 
                f.filename.includes('prompt') && 
                (f.filename.endsWith('.md') || f.filename.endsWith('.txt'))
              );
              
              if (promptFiles.length === 0) {
                await octokit.issues.createComment({
                  owner: OWNER,
                  repo: REPO,
                  issue_number: PR_NUMBER,
                  body: 'âŒ No prompt files found in this PR'
                });
                return;
              }
              
              // Detect domain from filename and content
              let domain = null;
              
              for (const file of promptFiles) {
                const newContent = await getFileContent(octokit, OWNER, REPO, file.filename, null, 'head');
                
                // Try to detect domain from filename or content
                if (file.filename.includes('security') || newContent.toLowerCase().includes('security') ||
                   newContent.toLowerCase().includes('risk') || newContent.toLowerCase().includes('safety')) {
                  domain = 'security';
                } else if (file.filename.includes('code') || file.filename.includes('programming') || 
                         newContent.toLowerCase().includes('code review') || newContent.toLowerCase().includes('programming') ||
                         newContent.toLowerCase().includes('javascript') || newContent.toLowerCase().includes('python') ||
                         newContent.toLowerCase().includes('java') || newContent.toLowerCase().includes('react') ||
                         newContent.toLowerCase().includes('api') || newContent.toLowerCase().includes('function') ||
                         newContent.toLowerCase().includes('algorithm') || newContent.toLowerCase().includes('debug')) {
                  domain = 'programming';
                } else if (file.filename.includes('data') || newContent.toLowerCase().includes('data analysis') ||
                          newContent.toLowerCase().includes('analytics') || newContent.toLowerCase().includes('visualization')) {
                  domain = 'data-analysis';
                } else if (file.filename.includes('financial') || newContent.toLowerCase().includes('financial') ||
                          newContent.toLowerCase().includes('finance') || newContent.toLowerCase().includes('budget') ||
                          newContent.toLowerCase().includes('investment') || newContent.toLowerCase().includes('money')) {
                  domain = 'financial';
                } else {
                  // Default to general purpose expert for unmatched prompts
                  domain = 'general';
                }
                
                if (domain) break;
              }
              
              // Domain detection now always succeeds with 'general' as fallback
              
              // Load MD-based expert definition
              const expertPath = path.join(__dirname, 'expert-definitions', `${domain}-expert.md`);
              
              if (!fs.existsSync(expertPath)) {
                await octokit.issues.createComment({
                  owner: OWNER,
                  repo: REPO,
                  issue_number: PR_NUMBER,
                  body: `âš ï¸ No expert definition found for domain: ${domain}. Please check available experts in expert-definitions/.`
                });
                return;
              }
              
              // Read expert definition
              const expertDefinition = fs.readFileSync(expertPath, 'utf-8');
              
              // Create MD-based expert module
              const expertModule = {
                name: `${domain.charAt(0).toUpperCase() + domain.slice(1)} Expert`,
                definition: expertDefinition,
                async evaluatePrompts(oldContent, newContent, anthropic) {
                  // Use 3-thread evaluation model as designed
                  
                  // Thread A: Evaluate current prompt
                  const threadA = await anthropic.messages.create({
                    model: 'claude-3-5-sonnet-20241022',
                    max_tokens: 4000,
                    messages: [{
                      role: 'user',
                      content: `You are primed with this prompt definition:\n\n${oldContent}\n\nNow respond to this test scenario: "Analyze the command 'sudo rm -rf /var/lib/docker' in a production environment"`
                    }]
                  });
                  
                  // Thread B: Evaluate new prompt  
                  const threadB = await anthropic.messages.create({
                    model: 'claude-3-5-sonnet-20241022',
                    max_tokens: 4000,
                    messages: [{
                      role: 'user',
                      content: `You are primed with this prompt definition:\n\n${newContent}\n\nNow respond to this test scenario: "Analyze the command 'sudo rm -rf /var/lib/docker' in a production environment"`
                    }]
                  });
                  
                  // Thread C: Expert comparison
                  const comparison = await anthropic.messages.create({
                    model: 'claude-3-5-sonnet-20241022',
                    max_tokens: 4000,
                    messages: [{
                      role: 'user',
                      content: `${expertDefinition}\n\n## Evaluation Task\n\nCompare these two security prompt responses:\n\n**Candidate A (Current):**\n${threadA.content[0].text}\n\n**Candidate B (Proposed):**\n${threadB.content[0].text}\n\nProvide a detailed evaluation and make a binary decision: APPROVE (merge PR) or REQUEST_CHANGES (close PR).`
                    }]
                  });
                  
                  const expertResponse = comparison.content[0].text;
                  const recommendation = expertResponse.toLowerCase().includes('approve') ? 'APPROVE' : 'REQUEST_CHANGES';
                  
                  return {
                    report: `### ðŸ” 3-Thread Evaluation Results\n\n**Test Scenario:**\n"Analyze the command 'sudo rm -rf /var/lib/docker' in a production environment"\n\n**Thread A (Current Prompt Response):**\n${threadA.content[0].text}\n\n**Thread B (Proposed Prompt Response):**\n${threadB.content[0].text}\n\n**Thread C (Expert Analysis):**\n${expertResponse}\n\n`,
                    recommendation: recommendation,
                    improvement: recommendation === 'APPROVE' ? 1 : 0
                  };
                }
              };
              
              // Process each changed file
              let fullReport = `## ðŸ¦ Prompt Expert Bank - Evaluation Report\n\n`;
              fullReport += `*Domain Expert: ${expertModule.name || domain}*\n`;
              fullReport += `*Timestamp: ${new Date().toISOString()}*\n\n`;
              
              let overallRecommendation = 'APPROVE';
              let totalImprovement = 0;
              
              for (const file of promptFiles) {
                fullReport += `## ðŸ“„ File: ${file.filename}\n\n`;
                fullReport += `### Change Summary\n`;
                fullReport += `- **Status**: ${file.status}\n`;
                fullReport += `- **Lines changed**: +${file.additions} -${file.deletions}\n\n`;
                
                // Get the old and new content
                const oldContent = file.status === 'added' ? '' : await getFileContent(octokit, OWNER, REPO, file.filename, file.previous_filename, 'base');
                const newContent = await getFileContent(octokit, OWNER, REPO, file.filename, null, 'head');
                
                // Use expert module to evaluate
                const evaluation = await expertModule.evaluatePrompts(oldContent, newContent, anthropic);
                
                // Add evaluation results to report
                fullReport += evaluation.report || '### Evaluation Results\n\nNo detailed report provided by expert module.\n\n';
                
                // Update overall recommendation based on expert evaluation
                if (evaluation.recommendation === 'REJECT' || evaluation.recommendation === 'REQUEST_CHANGES') {
                  overallRecommendation = 'REQUEST_CHANGES';
                }
                
                if (evaluation.improvement !== undefined) {
                  totalImprovement += evaluation.improvement;
                }
              }
              
              // Add final recommendation - NEVER NEUTRAL
              fullReport += `## ðŸŽ¯ Final Recommendation\n\n`;
              
              if (overallRecommendation === 'APPROVE') {
                fullReport += `### âœ… APPROVE\n\n`;
                fullReport += `The changes are acceptable and ready for merge.\n\n`;
                fullReport += `**Ready to merge** âœ…`;
              } else {
                // All non-APPROVE cases become REQUEST_CHANGES
                fullReport += `### âŒ REQUEST CHANGES\n\n`;
                fullReport += `The changes need improvement before merging.\n\n`;
                fullReport += `**Needs revision** âŒ`;
              }
              
              // Post comment
              await octokit.issues.createComment({
                owner: OWNER,
                repo: REPO,
                issue_number: PR_NUMBER,
                body: fullReport
              });
              
              // Auto-close PR if not approved and auto-close is enabled
              const autoCloseOnFail = process.env.AUTO_CLOSE_ON_FAIL !== 'false';
              if (overallRecommendation !== 'APPROVE' && autoCloseOnFail) {
                console.log('Closing PR due to failed evaluation...');
                await octokit.pulls.update({
                  owner: OWNER,
                  repo: REPO,
                  pull_number: PR_NUMBER,
                  state: 'closed'
                });
                
                await octokit.issues.createComment({
                  owner: OWNER,
                  repo: REPO,
                  issue_number: PR_NUMBER,
                  body: `ðŸš« **PR automatically closed** due to failed security evaluation.\n\nPlease address the feedback above and submit a new PR with the improvements.`
                });
              }
              
              console.log('Evaluation completed successfully');
              
            } catch (error) {
              console.error('Evaluation error:', error);
              await octokit.issues.createComment({
                owner: OWNER,
                repo: REPO,
                issue_number: PR_NUMBER,
                body: `âŒ Evaluation failed: ${error.message}`
              });
              throw error;
            }
          }
          
          async function getFileContent(octokit, owner, repo, path, previousPath, refType) {
            try {
              let ref;
              if (refType === 'head') {
                // Get from PR branch
                ref = `refs/pull/${process.env.PR_NUMBER}/head`;
              } else if (refType === 'base') {
                // Get from base branch
                ref = process.env.GITHUB_BASE_REF || 'main';
              } else {
                // Default behavior
                ref = process.env.GITHUB_BASE_REF || 'main';
              }
              
              const { data } = await octokit.repos.getContent({
                owner: owner,
                repo: repo,
                path: previousPath || path,
                ref: ref
              });
              
              if (data.content) {
                return Buffer.from(data.content, 'base64').toString('utf-8');
              }
            } catch (error) {
              console.log(`Could not fetch previous version of ${path}: ${error.message}`);
            }
            return '';
          }
          
          evaluate().catch(err => {
            console.error(err);
            process.exit(1);
          });
          EOF
          
          # Run evaluation
          OWNER="${OWNER}" REPO="${REPO}" PR_NUMBER="${{ inputs.pr-number }}" GITHUB_BASE_REF="${{ github.base_ref }}" AUTO_CLOSE_ON_FAIL="${{ inputs.auto-close-on-fail }}" node evaluate.js